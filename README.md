## 0 项目相关

#### 0.1 redis的持久化，你在项目中用了哪个，为什么？



#### 0.2 mysql你项目中做过哪些优化?


#### 0.3 java垃圾回收？


#### 0.4 Redis + Lua 在其中起到什么作用？



#### 0.5 Redis 缓存预热结构是怎样的？怎么判断用户状态？

#### 0.6 用KafKa的目的是什么？为什么不是直接操作数据库？

#### 0.7 KafKa消费失败的情况下你是怎么处理的？有重试机制吗？

#### 0.8 redis成功执行写入了但KafKa落库消费失败怎么办？Redis 写成功就代表成功吗？

#### 0.9 JWT 是怎么生成和校验的？用了什么加密算法？

#### 0.10 用户主动登出是怎么实现的？

#### 0.11 Redis 的原子性是怎么保证的？

#### 0.12 建立索引有什么原则？如何判断字段是否适合建索引？

#### 0.13 用“性别”字段建索引合适吗？为啥说选择性低不适合？

#### 0.14 全表扫描和使用区分度低的索引扫描哪种情况下更快？

#### 0.15 大分页 offset 性能差怎么优化？




## 1.滴滴秋储一面

#### 1.1 用户态和内核态的区别？

>用户态不能访问硬件和关键资源，只能访问用户空间内存，内核态可以直接访问全部的资源和内存；
>用户态通过调用申请内核服务，内核态直接使用；
>用户态的程序崩溃不影响系统，内核态崩溃可能导致系统崩溃；
>二者通过中断、异常和系统调用切换；

#### 1.2用户态怎么切换到内核态？

> 系统调用，如软中断和专用指令；
> 硬件中断，由外部设备触发，如鼠标；
> 异常，cpu执行指令时发生错误，如除零

#### 1.3进程之间如何通信？

> 管道：单向通信，基于字节流。匿名管道只能用于有亲缘关系的进程，命名管道可跨无关进程。
> 消息队列：内核维护的链表结构，可异步通信，无需同步，可独立读写，但消息大小受限。
> 共享内存：速度快，但是需要配合信号量和锁。
> 信号：内核向进程发起通知，但不能传数据。
> 信号量：计数器，用于进程间同步。
> 套接字：支持跨网通信和本地进程。
> 文件锁：对文件加锁进行多线程访问。

#### 1.4讲一下jvm的内存模型?

> 主要分为**线程私有**和**共有**两个部分
>
> * 私有：
>   * 程序计数器：记录线程执行的位置；
>   * Java虚拟机栈：存储方法调用和执行；
>   * 本地方法栈：为Native方法服务；
> * 共有：
>   * 堆：线程共享数据区，存放对象实例和数组；
>   * 方法区：存储呗虚拟机加载的类、常量、静态变量等；
>     * 运行时常量池：方法区的一部分；

#### 1.5 synchronized了解吗？

> 基本的线程同步机制，提供互斥、可见和可重入性。用于方法和代码块；
> 与volatile的区别：
> 	* s保证代码块的原子性；v只保证单次读写的原子性；
> 	* s保证有序性；v一定程度上保证（禁止指令重排）；
> 	* s会阻塞线程；v不会；
> 	* s用于代码块；v用于变量；

#### 1.6 偏向锁和轻量锁的区别？

> **偏向锁**针对只有一个线程访问同步块的场景优化；**轻量锁**针对有多个线程交替访问同步块的场景；
> **偏向锁**加锁无额外开销，解锁有较大开销；**轻量锁**无竞争时性能接近偏向锁，有竞争时会进行自旋（忙等待），消耗cpu，适用于低并发；
> 当第一个线程上**偏向锁**时，再来第二个线程，会升级为**轻量锁**；当**轻量锁**自旋失败，会升级为**重量级锁**；

#### 1.7 Arraylist和linkdlist的区别是什么

> a基于动态数组实现，支持通过索引快速随机访问；l基于双向链表实现；
> a默认初始容量为10，扩容时增加50%；
> 基于链表和数组的特性导致的时间开销（随机访问、头插、尾插、中间插入、内存占用）；

#### 1.8 arraylist线程安全吗？如果不安全应该用什么？

> 不安全，不是原子性的，可以使用：
> Collections.synchronizedList：原理：所有的方法加synchronized锁；
> 高并发性能较差，串行访问；
> CopywriteArrayList：原理：读写分离，适合读多写少场景；
> 读操作无锁性能高、写操作线程安全；写操作开销大，不适合频繁修改场景。
> Vector：原理：所有方法加synchronized锁；
> 已过时，不推荐。

#### 1.9 对不可变类写时复制的理解？

> **不可变类**：实例创建后状态不能修改的类（String、Interger），每次修改都会返回一个新对象。
> 特点：所有字段用final修饰、不提供setter方法、类本身声明为final。
> 优势：线程安全
> **写时复制**：一种延迟复制的优化策略，适用于读多写少场景，读操作无需加锁（如CopyOnWriteArraylist、CopyOnWriteArraySet），写操作加锁。

#### 1.10 CopyOnArrayList有什么缺点？

> 采用写时复制：写操作性能差，每次修改都会复制底层数据，内存和cpu占用高，使用场景受限（读多写少）；
> 弱一致性：读操作访问旧数据，可能访问到未修改的数据；迭代器基于创建时的数组快照，无法感知后续修改；
> 不支持实时检测：调用迭代器后，其他线程修改列表，不会报错，也看不见新数据；
> 批量写效率低；

#### 1.11 Mysql的索引分类？

> 按照数据结构：B+Tree索引、Hash索引、全文索引、R—Tree索引（空间索引）；
> 按照物理存储分类：聚簇索引、非聚簇索引；
> 按照应用维度：主键、普通、唯一、全文、前缀、降序、函数索引

#### 1.12 InnoDB和MyISAM执行语句哪个快？

> select:InnoDB需要处理事务稍慢；
> insert、update、delete：innodb支持行锁并发高更快，后者表锁；
> 全表扫描：前者遍历聚簇索引慢，后者直接读取顺序文件；
> count：前者扫描行或二级索引慢，后者直接存储总行数；

#### 1.13 索引失效的情况？

>违反最左前缀原则；对索引列使用函数或运算；隐式类型转换；使用！=或<>；
>使用is null或is not nul；使用like以通配符开头；数据分布不均导致优化器放弃索引；使用not in或 not exists。

#### 1.14 MySQL三种日志的作用？

> 二进制日志：主从复制基础、时间点恢复、记录数据变更；
> 重做日志：崩溃恢复、性能优化、WAL技术实现；
> 回滚日志：事务回滚、MVCC实现、保证原子性




## 2. 科大讯飞后端一面

#### 2.1 讲一下集合的框架

> Collection：
>
> * **List**：
>   * ArrayList（动态数组、线程不安全、数组特性、扩容机制1.5倍）、
>   * LinkedList（双向链表、线程不安全、链表特性、无扩容）、
>   * Vector（动态数组、线程安全、扩容机制2倍）；
> * **Set**：
>   * HashSet（底层HashMap、元素顺序无序、允许null、增删查O(1)）;
>   * LinkedHashSet（底层LinkedHashMap、元素按照插入顺序、允许null值、增删改O(1)）
>   * TreeSet（底层TreeMap、元素自然排序、不允许null(除非比较器允许)、增删改O(n)）
> * **Queue**：【ArrayDeque、LinkedList】；
>   Map：SortedMap；
>   * HashMap（数组+链表/红黑树、键无序且允许null、线程不安全、扩容机制2倍）、
>   * LinkedHashMap（同HashMap+双向链表、键插入顺序/访问顺序且允许null、线程不安全、扩容2倍）、
>   * TreeMap（红黑树、键排序且不允许null、线程不安全、无扩容）
>   * HashTable（数组+链表、键无序且不允许null、线程安全、扩容2n+1）

#### 2.2 ConcurrentHashMap和HashMap的区别是什么？

> HashMap：线程不安全、无同步机制、可能抛出并发修改异常、允许null键值；
> ConcurrentHashMap：线程安全、分段锁（jdk8改成了Node数组+cas+syn）、不会抛出并发修改异常、不允许null键值；

#### 2.3 stringbuffer和Stringbuilder有什么区别？

> buffer：线程安全（用syn修饰所有公共方法）、有同步开销、较慢、初始为16自动扩容；
> builder：线程不安全、无同步开销、速度快、初始为16自动扩容；

#### 2.4 线程池创建方式和参数？

> 通过**ExecutorService**工厂类创建（不推荐，隐藏了关键参数配置）
> 通过**ThreadPoolExecutor**：
>
> | 参数名          | 类型                      | 说明                                           |
> | --------------- | ------------------------- | ---------------------------------------------- |
> | corePoolSize    | int                       | 核心线程数，即使空闲也不会被回收的线程数量     |
> | maximumPoolSize | int                       | 最大线程数，线程池允许创建的最大线程数量       |
> | keepAliveTime   | long                      | 非核心线程的空闲存活时间（单位由TimeUnit指定） |
> | unit            | TimeUnit                  | 存活时间的单位（如TimeUnit.SECONDS）           |
> | workQueue       | BlockingQueue\<Runnable\> | 任务队列，用于保存等待执行的任务               |
> | threadFactory   | ThreadFactory             | 线程工厂，用于创建新线程                       |
> | handler         | RejectedExecutionHandler  | 拒绝策略，当任务无法被执行时的处理方式         |
>
> **工作队列类型:**
> LinkedBlockingQueue：无界队列（除非指定容量），可能导致OOM
> ArrayBlockingQueue：有界队列，需指定容量
> SynchronousQueue：不存储元素的队列，每个插入操作必须等待另一个线程的移除操作
> PriorityBlockingQueue：具有优先级的无界队列
> **拒绝策略:**
> AbortPolicy（默认）：直接抛出RejectedExecutionException异常
> CallerRunsPolicy：用调用者所在线程来运行任务
> DiscardPolicy：直接丢弃任务，不抛出异常
> DiscardOldestPolicy：丢弃队列中最老的任务，然后尝试重新提交当前任务

#### 2.5 synchronized和ReentrantLock的区别

> | 特性         | synchronized                                 | ReentrantLock                                                |
> | ------------ | -------------------------------------------- | ------------------------------------------------------------ |
> | **实现级别** | JVM 原生关键字                               | JDK 实现的类 (java.util.concurrent.locks)                    |
> | **锁的获取** | 自动获取和释放（进入同步块获取，退出时释放） | 必须显式调用 lock() 和 unlock()                              |
> | **锁的释放** | 由 JVM 自动管理（即使抛出异常也能保证释放）  | 必须在 finally 块中手动释放                                  |
> | **实现机制** | 基于 monitor 机制（对象头中的 Mark Word）    | 基于 AQS (AbstractQueuedSynchronizer) 实现                   |
> | **锁的类型** | 非公平锁（无法指定）                         | 可选择公平锁或非公平锁（构造参数指定）                       |
> | **获取方式** | 阻塞式获取，无法中断                         | 阻塞获取、尝试获取，立即返回成功/失败、超时等待获取、可中断获取 |
>
> 公平锁与非公平锁：获取锁的顺序是否遵循请求的先后顺序；

#### 2.6 双亲委派机制和优点？

>  **双亲委派机制**：当一个类加载器收到类加载请求时，首先不会自己尝试加载，而是将请求**委派给父类加载器**，这个委派操作会一直向上，直到启动类加载器（Bootstrap ClassLoader）。如果父加载器无法完成加载（在自己的搜索范围内找不到），子加载器才会尝试自己加载。
>
>  每次加载，会依次从启动类加载器、扩展类加载器和应用程序类加载器找；
>
>  **优点**：避免重复加载、核心类库由启动类加载器加载，不可被篡改（安全）、结构清晰。

#### 2.7 常见的类加载机制？

> 双亲委派模型
>
> 线程上下文类加载器（允许子加载器委托父加载器加载类）
>
> OSGi 模块化加载机制（每个模块（Bundle）使用独立的类加载器，实现模块化热部署）
>
> 自定义类加载器

#### 2.8 mysql有哪几种存储引擎？

> | 引擎                      | 事务支持 | 锁粒度 | 外键 | 适用场景          | 典型用途       |
> | ------------------------- | -------- | ------ | ---- | ----------------- | -------------- |
> | **InnoDB**（默认引擎）    | ✅        | 行级锁 | ✅    | 高并发 OLTP       | 订单、用户系统 |
> | **MyISAM**（传统引擎）    | ❌        | 表级锁 | ❌    | 读多写少          | 日志、全文搜索 |
> | **Memory**（内存引擎）    | ❌        | 表级锁 | ❌    | 临时数据/缓存     | 会话存储       |
> | **Archive**（归档引擎）   | ❌        | 行级锁 | ❌    | 历史数据归档      | 审计日志       |
> | **CSV**（文本引擎）       | ❌        | 表级锁 | ❌    | 数据交换          | 导出导入中间表 |
> | **NDB**（集群引擎）       | ✅        | 行级锁 | ❌    | 分布式集群        | 高可用实时系统 |
> | **Federated**（联邦引擎） | ❌        | 表级锁 | ❌    | 跨服务器查询      | 数据聚合       |
> | **Blackhole**（黑洞引擎） | ❌        | -      | ❌    | 数据丢弃/复制中继 | 主从复制       |

#### 2.9 介绍一下aop？

> 面向切面编程，通过**动态代理**或**字节码增强**技术，在不修改原有业务代码的情况下，增强方法的功能。
>
> **核心思想**
>
> - **关注点分离**：将与业务无关的代码（如日志、事务）抽离成独立的模块。
> - **动态织入**：在运行时或编译期将增强代码插入目标方法。
>
> **优点**：
>
>  **解耦横切逻辑**：业务代码更纯净。
>  **复用性高**：一个切面可应用于多个方法。
>  **灵活扩展**：动态增强功能，无需修改源码。
>
> | 场景         | 实现方式                          |
> | ------------ | --------------------------------- |
> | **日志记录** | `@Around` 记录方法入参和返回值    |
> | **事务管理** | `@Transactional`（Spring 已封装） |
> | **权限校验** | `@Before` 拦截未授权请求          |
> | **性能监控** | `@Around` 统计方法执行时间        |
> | **缓存管理** | `@Around` 查询缓存或更新缓存      |

#### 2.10 spring如何解决循环依赖问题？

> Spring 通过 **三级缓存（3-level cache）** 和 **提前暴露对象** 的机制解决循环依赖问题。
>
> | 缓存级别                                | 存储内容                      | 作用                                                  |
> | --------------------------------------- | ----------------------------- | ----------------------------------------------------- |
> | **一级缓存**（`singletonObjects`）      | 完全初始化后的 Bean           | 存放最终可用的 Bean，避免重复创建。                   |
> | **二级缓存**（`earlySingletonObjects`） | 早期暴露的 Bean（未填充属性） | 解决循环依赖时，临时存放半成品 Bean。                 |
> | **三级缓存**（`singletonFactories`）    | Bean 工厂（`ObjectFactory`）  | 生成早期 Bean 的代理对象（用于处理 AOP 代理等场景）。 |



## 3 杂七杂八

#### 3.1 **JVM 的 GC（垃圾回收）机制**

> javaguid

#### 3.2 java锁？

> **隐式锁：synchronized**：基于 对象监视器（Monitor） 实现，无需手动释放锁；缺点：不可中断、非公平锁、不支持超时。
>
> **显式锁：Lock 接口**：如**`ReentrantLock`**
>
> 
>
> 概念：
>
> > **乐观锁 vs 悲观锁**
> >
> > - **悲观锁**：假定并发冲突高（如 `synchronized`、`ReentrantLock`）。
> > - **乐观锁**：假定冲突少，通过 CAS 实现（如 `AtomicInteger`）。
>
> 
>
> **基础锁**：`synchronized` 简单高效，适合大多数场景。
>
> **高级锁**：`ReentrantLock` 提供更灵活的控制。
>
> **读写锁**：`ReadWriteLock` 优化读多写少场景。
>
> **无锁编程**：`CAS` 是高性能并发的终极方案。

#### 3.3 mysql怎么排查慢查询？

> **慢查询**是指执行时间超过预设阈值的 SQL 语句。
>
> **开启慢查询日志**、**实时监控慢查询**、**分析慢查询日志**

#### 3.4 缓存穿透、缓存击穿、缓存雪崩详解

> * **缓存穿透**：查询一个**根本不存在的数据**，导致请求直接穿透缓存层到达数据库，造成数据库压力过大。
>
>   * 解决方案：
>     * 缓存空对象（设置较短过期时间）
>     * 布隆过滤器
>
> * **缓存击穿**：**某个热点key突然失效**，导致大量请求直接打到数据库，造成数据库瞬时压力过大。
>
>   * 与穿透的区别
>     - 穿透：查询的数据**根本不存在**
>     - 击穿：查询的数据**存在但缓存失效**
>
>   * 解决方法：
>     * 互斥锁：当缓存失效时，**只允许一个线程去查询数据库**
>     * 逻辑过期：**不设置物理过期时间**，而是**在数据中存储一个逻辑过期时间**，当发现数据过期时，**异步更新缓存**，并继续返回旧数据，避免阻塞请求
>     * 永不过期：**缓存不设置过期时间**，而是**通过后台任务定期更新缓存**，确保热点数据始终可用。
>
> * **缓存雪崩**：**大量缓存key同时失效**，导致所有请求直接访问数据库，造成数据库崩溃。
>
>   * 解决方法：随机过期时间、多级缓存、熔断降级



## 4 用友java暑期实习一面

#### 4.1 http和https区别？

> | 特性       | HTTP (超文本传输协议) | HTTPS (安全超文本传输协议) |
> | ---------- | --------------------- | -------------------------- |
> | **安全性** | 不加密，明文传输      | 加密传输，安全性高         |
> | **端口**   | 默认端口 80           | 默认端口 443               |
> | **协议层** | 应用层协议            | HTTP + SSL/TLS 加密层      |
>
> HTTPS增加约10%的CPU计算负载
>
> HTTP和HTTPS核心区别在于安全性。HTTP是明文传输，而HTTPS通过SSL/TLS实现加密。具体来说：
>
> 1. HTTPS需要CA（机构）签发的数字证书验证身份；
> 2. 建立连接时通过非对称加密交换密钥，之后用对称加密传输数据；
> 3. 默认端口443，且现代浏览器会对非HTTPS页面标记不安全。

#### 4.2 redis为什么快

> * 内存存储：io、寻址快；
>
> * 高效数据结构设计：
>
>   * 动态字符串(SDS)：预分配空间
>   * 哈希表(dict)：渐进式rehash、自动扩容；
>   * 跳跃表：有序集合实现；
>
> * 单线程架构：
>
>   * 避免多线程的锁开销和上下文切换；
>   * 单命令天然具备原子性；
>   * 无CPU缓存失效；
>   * 配合I/O多路复用
>
> * I/O多路复用技术：使用**epoll/kqueue**系统调用实现高并发
>
>   | 模型         | 连接数限制 | CPU利用率 | 实现复杂度 |
>   | ------------ | ---------- | --------- | ---------- |
>   | 阻塞I/O      | 约1000线程 | 低        | 简单       |
>   | select/poll  | 约1024连接 | 中        | 中等       |
>   | epoll/kqueue | 10万+连接  | 高        | 复杂       |
>
> * 精心优化的网络协议：二进制安全（支持任何字符集）、极简解析。
>
> * 持久化优化策略：提供两种持久化方式且不影响性能
>
>   | **方式** | **原理**                   | **性能影响**          |
>   | -------- | -------------------------- | --------------------- |
>   | RDB快照  | 定时fork子进程全量备份     | 主进程几乎不受影响    |
>   | AOF日志  | 追加写入（可配置每秒同步） | fsync策略决定开销大小 |

####  4.3 springbootapplication注解的组成

> `@SpringBootApplication`是Spring Boot最核心的注解，它是一个**复合注解**，由三个关键注解组合而成，提供了Spring Boot应用的默认配置和自动装配能力。
>
> **源码：**
>
> ```java
> @Target(ElementType.TYPE)
> @Retention(RetentionPolicy.RUNTIME)
> @Documented
> @Inherited
> @SpringBootConfiguration
> @EnableAutoConfiguration
> @ComponentScan(excludeFilters = {
>  @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class),
>  @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) 
> })
> public @interface SpringBootApplication {
>  // 省略其他属性...
> }
> ```
>
> * (1) `@SpringBootConfiguration`
>   - **作用**：标识当前类为配置类
>   - **本质**：是`@Configuration`的特化版本
> * (2) `@EnableAutoConfiguration`
>   - **作用**：启用Spring Boot的自动配置机制
>   - **实现原理：**
>     - 通过`@Import(AutoConfigurationImportSelector.class)`加载自动配置
>     - 从`META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports`加载配置类
>     - 基于条件注解（如`@ConditionalOnClass`）决定是否生效
> * (3) `@ComponentScan`
>   - **作用**：自动扫描组件
>   - **默认行为：**
>     - 扫描当前包及其子包
>     - 包含`@Component`, `@Service`, `@Repository`, `@Controller`等注解的类

#### 4.4 三次握手

> ![image-20250505104611021](https://github.com/user-attachments/assets/678ea9ea-1563-43b3-96e8-bcf584ba2f68)

>
> | 握手次数 | 解决的问题         | 如果缺少会怎样                 |
> | -------- | ------------------ | ------------------------------ |
> | 第一次   | 客户端发送能力正常 | 服务器无法确认客户端存在       |
> | 第二次   | 服务器收发能力正常 | 客户端无法确认服务器存在       |
> | 第三次   | 客户端接收能力正常 | 服务器无法确认客户端能接收数据 |
>
> - 前两个SYN包**不能**携带应用数据（RFC 793规定）
> - 第三次ACK**可以**携带数据（TCP Fast Open特性除外）

#### 4.5 mysql的锁的种类

> **按锁粒度分类**：
>
> * 全局锁（数据库实例）；
> * 表级锁；
> * 行级锁：记录锁（索引记录）、间隙锁（索引记录之间的间隙，防止幻读）、 临键锁（记录锁 + 间隙锁）、插入意向锁（插入操作前设置，多个事务不冲突时可同时持有）；
>
> **按锁模式分类**：共享锁（多个事务可同时持有）、 排他锁、意向锁（意向共享锁、意向排他锁，快速判断表内是否有行锁）、
>
> **特殊锁类型**：自增锁（自增列插入时）、谓词锁（空间索引）

#### 4.6 mysql索引、主键、唯一索引、联合索引区别

> | 索引类型 | 关键特性                   | 是否允许NULL | 数量限制  | 是否聚簇      | 典型应用场景                   |
> | -------- | -------------------------- | ------------ | --------- | ------------- | ------------------------------ |
> | 主键索引 | 唯一标识记录，NOT NULL约束 | ❌不允许      | 每表仅1个 | ✅(InnoDB)     | 表的主标识字段                 |
> | 唯一索引 | 保证列值唯一性             | ✅允许        | 每表多个  | ❌             | 业务唯一约束(如用户名、手机号) |
> | 普通索引 | 加速查询，无约束           | ✅允许        | 无限制    | ❌             | 高频查询字段                   |
> | 联合索引 | 多列组合的索引结构         | 依列属性而定 | 无限制    | ❌(除非是主键) | 多条件组合查询                 |

#### 4.7 innodb的事务隔离级别

> | 隔离级别             | 脏读 | 不可重复读 | 幻读 | 并发性能 | 实现机制                 |
> | -------------------- | ---- | ---------- | ---- | -------- | ------------------------ |
> | READ UNCOMMITTED     | ❌    | ❌          | ❌    | 最高     | 无锁读取                 |
> | READ COMMITTED (RC)  | ✅    | ❌          | ❌    | 高       | 快照读 + 记录锁          |
> | REPEATABLE READ (RR) | ✅    | ✅          | ⚠️    | 中       | 快照读 + 记录锁 + 间隙锁 |
> | SERIALIZABLE         | ✅    | ✅          | ✅    | 最低     | 全表锁/自动加共享锁      |
>
> ✅ = 防止;  ❌ = 不防止;  ⚠️ = InnoDB特殊处理可防止



## 5 PDD 暑期实习 二面面经

#### 5.1 布隆过滤器误判原理?如何减少误判率?

> 使用**多个哈希函数**对元素进行映射。判断存在，可能误判；判断不存在，一定不存在。
>
> 降低误判率的五大核心策略：增大位数组容量(m)、 优化哈希函数数量（）、选择高质量的哈希函数、动态扩容方案（分层-第一层超过阈值用两层，Scalable Bloom Filter）、数据预热优化

#### 5.2 CAS的思想?

>  CAS（Compare-And-Swap）是一种**无锁并发原子操作**，
>
>  核心思想：当需要修改某个共享变量的值时，先比较该变量当前值是否与预期值（读取时的旧值）一致，若一致则原子性地更新为新值，否则放弃操作（通常配合重试机制）。

#### 5.3 java的volatile?能保证线程安全吗?

> * 轻量级同步机制，提供两大保证：
>
> 1. 可见性保证：对volatile变量的写操作会立即刷新到主内存，读操作会直接从主内存读取最新值；
> 2. 禁止指令重排序：编译器/runtime/CPU不会对volatile变量的操作与其他内存操作进行重排序；
>
> * 不能完全保证线程安全。
>   * 可以保证--（单一写多读场景）；
>   * 不能保证--（复合操作：任何需要"读取-修改-写入"的操作
>
> ​					  多线程写操作：多个线程同时修改volatile变量
>
> ​					  依赖当前值的操作：检查后执行(check-then-act)模式（如不变式约束））
>
> * **volatile** vs **synchronized**
>
>   | 特性     | volatile                | synchronized            |
>   | -------- | ----------------------- | ----------------------- |
>   | 原子性   | 仅保证单次读/写的原子性 | 保证代码块/方法的原子性 |
>   | 可见性   | 保证                    | 保证                    |
>   | 互斥性   | 不提供                  | 提供                    |
>   | 性能     | 更高                    | 较低（涉及锁获取/释放） |
>   | 适用场景 | 状态标志、一次性发布    | 复合操作、临界区保护    |
>
> * **正确使用volatile的建议**
>
>   1. 确保变量状态完全由其当前值决定
>   2. 变量不需要参与不变式约束（即不依赖其他变量的值）
>   3. 访问变量时不需要加锁
>   4. 变量不会被多个线程同时修改

#### 5.4 线程池的线程饥饿问题，解决方案?

> * 在线程池中，某些任务由于资源分配策略或调度问题而**长期得不到执行机会**的现象。这些任务虽然被提交到了线程池，但由于各种原因无法获取到线程资源来执行，导致任务积压或响应延迟。
> * 常见场景：固定大小线程池+长任务阻塞、不合理的任务优先级、资源死锁；
> * 解决方案：
>
>   * 合理配置线程池；
>   * 使用不同的线程池隔离任务（长、短任务）；
> * 设置任务超时时间；
>   * 使用工作窃取线程池；
> * 监控和预警；



## 6 航旅纵横java暑期实习

#### 6.1 redis的持久化机制？

> 主要通过两种方式实现：**RDB（Redis Database）** 和 **AOF（Append Only File）**实现；**RDB**：在指定时间间隔内将内存数据生成一个二进制快照文件（`dump.rdb`），保存的是键值对的全量数据。
>
> * 优点：恢复速度快、备份简单
>
> * 缺点：有数据丢失风险【两快照间数据可能因宕机丢失】、性能开销；
>
> **AOF**：记录所有写操作命令，以文本协议格式追加到文件末尾（`appendonly.aof`）。
>
> * 同步策略（通过 appendfsync 配置）：
>   * always：每次写操作后立即同步到磁盘（最安全，性能最低）。
>   * everysec：每秒批量同步一次（推荐，平衡安全与性能）。
>   * no：由操作系统决定何时同步（不可控，风险高）。
> * 优点：数据安全性更高【最多丢失 1 秒数据（everysec 模式）】、可读性强【AOF 文件为文本格式，可人工阅读和修复】；
> * 缺点：文件体积较大【比 RDB 大】、恢复速度较慢【需逐条执行】；
>
> **混合持久化：**以 RDB 格式存储全量数据，后续的写操作追加到 AOF 文件中。前半部分为 RDB 快照，后半部分为 AOF 日志。
>
> * 优点：
>   * 快速恢复：RDB 部分快速加载，AOF 部分补全最新数据。
>   * 数据安全：避免 RDB 的数据丢失问题，同时减少 AOF 重写开销。

#### 6.2 主从复制原理？

> Redis 的主从复制（Replication）：数据同步机制，通过将主节点（Master）的数据复制到一个或多个从节点（Slave）实现数据冗余、读写分离和故障恢复。
>
> 本质是 数据同步，分为 **全量同步** 和 **增量同步** 两个阶段，基于：
>
> * **异步复制**：主节点在写入数据后，异步将数据同步给从节点（默认模式，高性能但可能丢失少量数据）。
> * **基于偏移量的增量同步**：通过复制偏移量（`offset`）和复制积压缓冲区（`repl_backlog`）实现断点续传。
> * **心跳检测**：主从节点通过 `PING`/`PONG` 保持连接，检测网络健康状态。
> * 主从复制 vs. 集群
>
> | **特性**     | **主从复制**     | **Redis Cluster**    |
> | ------------ | ---------------- | -------------------- |
> | **数据分布** | 所有节点数据相同 | 数据分片（Sharding） |
> | **扩展性**   | 适合读扩展       | 支持读写扩展         |
> | **故障转移** | 需配合 Sentinel  | 内置自动故障转移     |

#### 6.3 缓存穿透、缓存击穿和缓存雪崩?

> 看3.4。

#### 6.2 线程池的参数有哪些?

> 参考上文；

#### 6.3 redis分布式锁的原理？
> 分布式锁：在分布式系统中，保证共享资源在任意时刻只能被一个客户端（或进程）访问。
> 最基础：利用 Redis 的 键（key）作为锁，并结合其特定的命令来实现。
> * 获取锁：SET lock_key unique_value NX EX seconds；
> * 释放锁：DEL lock_key；（客户端A获得锁，超时锁自动过期；B获得锁后A可能删除B的锁）【原子性安全释放锁：使用 Lua 脚本】

#### 6.4 MySQL怎么实现分布式锁，要设置哪些字段？
> * 基于唯一索引（乐观锁）：
>   * 实现：尝试插入记录（利用唯一索引冲突实现互斥），若锁不存在或已过期，插入成功即获取锁。若锁被其他客户端持有且未过期，插入失败。
>   * 字段：锁标识（如业务资源名）、锁持有者标识（如UUID）、锁过期时间；
> * 基于行锁（悲观锁）:
>   * 实现：类似唯一索引；
>   * 字段：锁标识、持有者标识；
> 但 MySQL 锁的性能和扩展性不如 Redis/ZooKeeper，适合低频或已有 MySQL 依赖的场景。

#### 6.5 哨兵集群里面的脑裂问题；怎么解决？
> 脑裂问题（Split-Brain）：因网络分区导致集群被分裂成多个独立的小集群，每个小集群可能误认为自己是主集群，导致多个主节点（Master）同时写入数据（部分客户端仍能连接旧主节点，导致数据写入不同主节点），引发数据不一致。
> 形成原因：网络分区、哨兵选举机制、客户端隔离
> 解决方法：
> * 配置 min-slaves-to-write 和 min-slaves-max-lag，确保主节点在从节点不足或同步延迟过高时拒绝写入。
> * 调整哨兵的 quorum 和 majority，避免少数派哨兵误判主节点故障。
> * 客户端降级策略，如检测到主节点异常时暂停写入。
> * 极端情况下手动干预，强制下线旧主节点，等待哨兵重新选举。


#### 6.6 MySQL B+树和B树的区别？
> * 为什么MySQL选择B+树？
>   MySQL的InnoDB引擎采用B+树，主要因其：
>   更适合磁盘存储（减少I/O）
>   天然支持高效范围查询
>   稳定的查询性能（时间复杂度稳定为O(log n)）
>
> | **特性**         | **B树**                                    | **B+树**                                       |
> | ---------------- | ------------------------------------------ | ---------------------------------------------- |
> | **数据存储位置** | 所有节点（包括非叶子节点）都可能存储数据   | **仅叶子节点存储数据**，非叶子节点只存索引     |
> | **叶子节点链接** | 叶子节点之间**无链表连接**                 | 叶子节点**通过双向链表连接**，支持顺序访问     |
> | **查询性能**     | 可能更快（命中非叶子节点时），但**不稳定** | **稳定**（必须到叶子节点），适合范围查询       |
> | **范围查询效率** | 低（需多次回溯树结构）                     | **高**（链表直接遍历相邻叶子节点）             |
> | **树高度**       | 相对较高（节点存储数据，键值更少）         | **更矮胖**（节点仅存索引，键值更多）           |
> | **磁盘I/O次数**  | 可能较多（树高较高）                       | **更少**（树高更低，非叶子节点可缓存更多索引） |
> | **适用场景**     | 随机读写（如文件系统）                     | **范围查询、顺序扫描**（如数据库索引）         |

#### 6.7 高可用场景题？
> 给商户发优惠券系统的管理端。有 10 万个商户会使用这个渠道，每个商户会拿着 10 万个手机号放到 Excel 表格里上传到管理端，你觉得这个流程该怎么做？以及我们要保证它的这个流程的高可用？
> 流程：
> * **文件上传与存储**
>   - **分片上传**：前端使用`WebUploader`或`Resumable.js`实现大文件分片上传，后端通过`Spring WebFlux`异步接收，避免阻塞。
>   - **临时存储**：上传文件暂存至分布式文件系统（如`FastDFS`或云存储OSS），记录文件元数据（商户ID、文件路径、任务ID）到MySQL。
>   - **异步触发**：上传完成后，向消息队列（如`Kafka`）发送解析任务事件，避免同步处理超时。
>  
> * **文件解析与校验**
>   - **流式解析**：使用`EasyExcel`或`Apache POI SXSSF`逐行读取Excel，降低内存占用。
>     - 数据校验：
>     - 手机号格式校验（正则表达式）。
>       - 去重处理：使用`Redis BloomFilter`预判重复手机号，结合数据库唯一索引二次校验。
>   - **数据分发**：解析后的手机号分批写入`Kafka`分区（按商户ID或手机号哈希分区），解耦数据处理压力。
>   
> * **数据处理与发券**
>   - **异步消费**：多组消费者（`Kafka Consumer Group`）从队列拉取数据，批量处理发券逻辑。
>     - **数据库写入**：采用`JDBC Batch`批量插入优化性能，结合`ShardingSphere`按商户ID分表存储。
>   - **幂等性保障**：通过数据库唯一索引（商户ID + 手机号）或`Redis Set`记录已发券标识，防止重复发券。
>
> * **任务状态追踪**
>   - **状态管理**：使用`Redis`存储任务进度（如已处理/失败数），支持商户实时查询。
>   - **失败重试**：消费失败的消息进入死信队列（DLQ），后续通过补偿任务重新处理。
>  
> 
> 高可用保证：
> * **系统架构分层**
>   - **接入层**：Nginx负载均衡 + Keepalived实现高可用，防止单点故障。
>   - **应用层**：Spring Boot微服务集群部署，通过Kubernetes（K8s）实现滚动更新与自动扩缩容。
>   - 存储层：
>     - **数据库**：MySQL主从复制 + 读写分离，使用MyCat或ShardingSphere分库分表。
>     - **缓存**：Redis Cluster集群部署，支持哨兵机制与持久化备份。
>     - **消息队列**：Kafka多副本机制，确保消息不丢失。
> * **高可用关键措施**
>   - **服务无状态化**：Session数据（如用户登录态）存储至Redis，服务实例可随时扩展。
>   - 限流与熔断：
>     - 使用`Sentinel`或`Hystrix`限制单用户请求频率，防止雪崩。
>     - 对核心接口（如发券）设置降级策略，异常时返回缓存数据或排队提示。
>   - 数据一致性：
>     - 最终一致性：通过Kafka事务或补偿任务（定时核对Redis与数据库记录）处理异常。
>     - 强一致性：发券操作涉及优惠券库存扣减时，采用分布式锁（Redis Lua脚本）或TCC事务。
> * **监控与灾备**
>   - **全链路监控**：Prometheus + Grafana监控JVM、数据库连接池、Kafka消费延迟等指标。
>   - **日志分析**：ELK（Elasticsearch + Logstash + Kibana）集中化日志管理，快速定位异常。
>   - 灾备方案：
>     - 数据库定期备份至S3或OSS，支持快速恢复。
>     - 跨可用区部署Kafka与Redis，保障区域故障时切换。
> * **性能优化技巧**
>   1. **批量处理**：合并数据库写入与发券请求，减少网络与IO开销。
>   2. **压缩与序列化**：使用Snappy或LZ4压缩Kafka消息，提升传输效率。
>   3. **热点数据预热**：对高频查询的商户数据提前加载到Redis。
>   4. **冷热分离**：历史数据归档至HBase或Elasticsearch，降低主库压力。


#### 6.8 有一个接口突然变的很慢，怎么快速解决；后续怎么排查原因?
> * 快速解决：
>   * 熔断降级:
>     * 立即启用熔断机制（如Hystrix/Sentinel）;
>     * 对非核心功能进行降级;
>   * 限流保护:使用Nginx或Sentinel进行限流;
>   * 横向扩容:Kubernetes快速扩容;
>   * 重启节点:逐步滚动重启服务节点
>     * 先重启负载最低节点;
>     * 观察5分钟无异常再继续;
>    
>   * 回滚代码
>  
> * 根本原因排查:
>   * 监控CPU占用排除系统问题；
>   * 分析线程状态；
>   * 数据块排查，开启慢查询，检查连接池是否不足；
>   * 缓存排查，检查缓存穿透/击穿
>   * 检查第三方接口超时：














## 7 京东零售-平台产品和研发中心后端一面

#### 7.1 说一下哈希表（HashMap）的实现原理？

> **数据结构：**数组+链表/红黑树结构【Java的HashMap底层是一个Node数组，每个数组元素是一个链表或红黑树(JDK8+)】
>
> 当多个key映射到同一数组索引时，形成链表；
>
> JDK8后，当链表长度超过8时转换为红黑树 (且![image](https://cdn.nlark.com/yuque/__latex/ab7db5447f82f79b14b90f97e2a7ec75.svg) 时)，当红黑树节点数<6时，转回链表。

#### 7.2  为什么链表长度为8时，要转换成红黑树？

> 经过测试和统计，当链表长度达到8时，红黑树的综合性能开始优于链表。



#### 7.3 什么情况会破坏双亲委派机制？

> + SPI（Service Provider Interface）服务发现机制：JDBC、JNDI等；
> + 热部署/热替换需求：OSGi框架、Tomcat等Web容器的JSP热部署、JRebel等热部署工具；
> + 用户自定义类加载器覆盖：实现自己的类加载逻辑、隔离不同模块的类加载；
> + Tomcat等Web容器的类加载设计；
> + OSGi的类加载机制；
> + 动态代理技术；

> + 核心接口由启动类加载器加载（如`java.sql.Driver`）
> + 实现类由应用类加载器加载
> + 需要父类加载器请求子类加载器完成类加载

> + 需要动态加载和卸载类
> + 不同版本的类可能需要并行存在
> + 传统的双亲委派无法满足这种灵活性

#### 7.4 说一下SPI和热加载？

> + SPI（Service Provider Interface）：Java提供的一种服务发现机制，允许第三方为接口提供实现，核心思想是**接口与实现分离**。
> + SPI工作原理：
>
> 
>
>     1. 定义接口【在核心库中定义服务接口】
>     2. 提供实现【在META-INF/services目录下创建以接口全限定名命名的文件】
>     3. 加载实现【通过`ServiceLoader`动态加载实现类】
>
> + 热加载是指在不重启应用的情况下，动态更新类或资源文件的能力。
> + 热加载实现原理：
>   1. 自定义类加载器【为每个需要热加载的模块创建独立的类加载器】
>   2. 类卸载机制【当类加载器被回收时，其加载的类才能被卸载】
>   3. 文件监控【监控class文件变化触发重新加载】

#### 7.5 说一下Java内存模型

> + Java内存模型（Java Memory Model, JMM）包括**主内存**与**工作内存**。
> + JMM定义了8种原子操作来控制主内存与工作内存之间的交互：lock（锁定）、unlock（解锁）、read（读取）、load（载入）、use（使用）、assign（赋值）、store（存储）、write（写入）
> + 三大特性：
>   - 原子性(Atomicity)
>     * 保证基本数据类型的访问读写是原子性的（除long/double）
>     * 通过`synchronized`和`Lock`保证代码块的原子性
>   - 可见性(Visibility)
>     * 一个线程修改了共享变量，其他线程能立即看到修改
>     * 实现方式：
>       + `volatile`关键字
>       + `synchronized`（解锁前必须同步到主内存）
>       + `final`（正确初始化后不可变）
>   - 有序性(Ordering)
>     * 禁止指令重排序优化
>     * 通过以下方式保证：
>       + `volatile`的禁止重排序语义
>       + `synchronized`的"一个变量同一时刻只允许一条线程对其lock"规则
>       + happens-before原则
> + happens-before原则（JMM定义的一系列保证内存可见性的规则）：
>   1. **程序顺序规则**：同一线程中的操作，前面的happens-before后面的
>   2. **监视器锁规则**：解锁操作happens-before后续的加锁操作
>   3. **volatile规则**：volatile变量的写操作happens-before后续的读操作
>   4. **线程启动规则**：Thread.start() happens-before线程中的任何操作
>   5. **线程终止规则**：线程中的所有操作happens-before其他线程检测到该线程已终止
>   6. **中断规则**：对线程interrupt()的调用happens-before被中断线程检测到中断
>   7. **终结器规则**：对象的构造函数happens-before它的finalize()方法
>   8. **传递性**：如果A happens-before B，且B happens-before C，那么A happens-before C
> + volatile关键字：保证变量的**可见性**、禁止指令**重排序**。



#### 7.6 为什么内存模型要这么划分，以及会出现哪些问题

> 为了解决多线程编程中的核心挑战；
>
> **原因：** 
>
> + 硬件层面：
>   - CPU缓存架构**：**cpu多级缓存导致内存访问速度不一致；
>   - 缓存一致性协议**：**不同硬件对缓存一致性协议实现不同；
>   - 指令重排序**：**CPU和编译器会优化指令执行顺序；
> + 性能优化：工作内存减少线程访问主内存的次数，提高性能；
> + 并发编程的复杂性：直接操作主内存会导致复杂的同步问题
>
> **可能会出现的问题：**
>
> + 可见性问题：【一个线程修改了共享变量，另一个线程看不到修改】修改只发生在工作内存，没有及时刷新到主内存。
> + 原子性问题：【操作被中途打断，导致结果不符合预期】除long/double外的基本类型读写是原子的，但复杂操作不是。
> + 有序性问题：【执行顺序与编写顺序不一致】指令重排序优化

#### 7.7 事务ACID特性都是怎么实现的？
> * **原子性(Atomicity)**：【Undo Log(回滚日志)】
> * **一致性(Consistency)：**【约束条件 + 应用层逻辑】
>   * **数据库层面**：
>     - 主键/唯一键约束
>     - 外键约束
>     - CHECK约束
>     - 非空约束
> * **隔离性(Isolation)**：【锁机制 + MVCC(多版本并发控制)】
>   * **锁机制**：
>     - 共享锁(S锁)：读锁，多个事务可同时持有
>     - 排他锁(X锁)：写锁，独占资源
>     - 意向锁：表级锁，提高锁检查效率
>   * **MVCC机制**：
>     - 每行数据维护多个版本
>     - 通过ReadView判断哪些版本对当前事务可见
>     - 解决读写冲突问题
> * **持久性(Durability)**：【Redo Log(重做日志) + 双写缓冲】
>   * **Redo Log**：
>     - 记录物理级别的页修改
>     - 采用追加写入方式，性能高
>     - 崩溃恢复时重放Redo Log
>   * **双写缓冲(Double Write)**：
>     - 防止页断裂问题
>     - 先将脏页写入双写缓冲区
>     - 再写入数据文件
>   * **刷盘策略**：
>     - 事务提交时强制刷Redo Log(innodb_flush_log_at_trx_commit=1)
>     - 定期刷脏页到磁盘

#### 7.8 慢查询了解多少？
> 执行时间超过预设阈值的数据库查询操作；
>
> **常见原因**：缺乏有效索引【导致全表扫描】、复杂查询设计【多表JOIN等】、不合理的写法【SELECT *、LIKE '%xxx%'模糊查询】、大数据量操作、锁竞争：长事务导致的锁等待；
>
> **影响**：数据库负载升高、连接池资源被长时间占用；
>
> **识别方式**：数据库慢查询日志、ORM框架日志、数据库监控；
>
> **优化策略**：索引优化、SQL重构、缓存应用、分页处理、读写分离；

#### 7.9 分库分表了解多少，会存在什么问题？
> 将一个数据库中的数据分散到多个数据库或表中，以解决单库单表数据量过大导致的性能瓶颈问题。
>
> **分为**：水平分表、垂直分表和分库；
>
> **常见策略**：范围分片【时间等】、哈希分片、目录分片和地理位置分片；
>
> **存在问题**：
>
> * 分布式事务问题：难以保证ACID特性、需引入分布式事务解决方案、增加了系统复杂度和性能开销；
> * 跨库JOIN问题：难以执行高效的关联查询、需要改为多次查询后在应用层合并；
> * 全局唯一ID生成：自增ID无法使用、需要引入分布式ID生成方案；
> * 分页排序问题：需在各分片查询后合并排序；
> * 扩容与数据迁移：数据迁移过程复杂且容易出错

#### 7.10 Redis会丢数据吗？ 除了持久化的丢数据，还有什么情况会丢数据
> **持久化相关的数据丢失**:
>   * RDB（快照）模式【手动执行SAVE/BGSAVE或配置的定时保存】:
>     风险点：两次快照之间的数据未持久化（宕机时丢失）、BGSAVE时子进程崩溃可能导致损坏的RDB文件。
>   * AOF（追加日志）模式【每条写操作同步、每秒同步（默认）、依赖操作系统刷盘】：
>     风险点：AOF重写（BGREWRITEAOF）期间宕机可能导致日志损坏、写AOF文件时磁盘满或权限问题。
>   * 混合持久化（Redis 4.0+）【RDB+AOF混合模式】：
>     但仍可能丢失最后一次RDB快照后的增量数据。
>
> **非持久化相关的数据丢失**：
> * 内存不足时的淘汰策略：内存不足时导致数据“被动丢失”；
> * 主从复制延迟：
>   异步复制【主节点写入后未同步到从节点时主节点宕机，即使启用故障转移（哨兵/集群），从节点可能缺失部分数据。】；
>   脑裂问题【网络分区导致旧主节点继续接受写入，恢复后数据被覆盖（需配置min-slaves-to-write避免）】；
> * 人为操作失误：误执行指令、错误配置；
> * 集群模式下的风险：
>   哈希槽迁移过程中节点宕机，可能导致部分键丢失；
>   多副本配置不足时（如cluster-require-full-coverage no），部分分片不可用；
> * 客户端确认缺失：非原子操作（如LPUSH+EXPIRE）时部分命令失败、客户端未正确处理写操作的响应（如网络超时但实际写入成功）。

#### 7.11 Redis的缓存雪崩、缓存击穿和缓存穿透
> 看前面

#### 7.12 生产者消费者模型的应用场景
> 用于需要缓冲、异步、并行或事件驱动的场景，从简单的多线程任务分配到复杂的分布式系统，几乎覆盖所有高并发领域。
> * 解耦：生产者和消费者无需知道彼此存在，通过队列通信。
> * 弹性伸缩：可独立扩展生产者或消费者数量。
> * 容错性：队列持久化可防止任务丢失（如RabbitMQ的ACK机制）。
> * 顺序控制：通过队列实现先进先出（FIFO）或优先级调度。

#### 7.13 简单说一下IoC和AOP，没有IoC会怎么样？
> **AOP**：看2.9；
> **IoC(控制反转)**：将对象的创建、依赖管理交给框架（容器）而非程序员手动控制。
> * 实现方式：
>   依赖注入（DI）：通过构造函数、Setter 或注解（如 @Autowired）自动注入依赖对象;
>   依赖查找：从容器中主动获取对象（如 ApplicationContext.getBean()）。
>
> **没有 IoC 会怎样？**
> * 对象需手动 new 创建：依赖关系硬编码在代码中，修改依赖时要改动大量代码；
> * 依赖真实对象：无法轻松替换为测试用的Mock（如数据库、第三方服务）；
> * 生命周期管理复杂：需手动完成；
> * AOP 难以实现：AOP 依赖动态代理，而动态代理通常由 IoC 容器创建代理对象。；


# 8 字节一面
#### 8.1 lua脚本有什么缺点？
> * 解释型语言：计算密集时表现差；
> *  生态系统较小：库支持有限、工具链薄弱；
> *  语言设计上的局限性：数组索引从 1 开始、弱类型系统【误将字符串当数字计算】；
> *  多线程支持差：不适合大型项目，缺乏模块化支持、代码重构困难；
> *  嵌入依赖性强：依赖宿主程序；

#### 8.2 rabbitmq，如何保证可靠性?
> **生产者可靠性（确保消息成功投递）**：开启生产者确认、事务模式（不推荐，性能差）；
> **消息队列可靠性（确保消息不丢失）**：队列持久化、消息持久化、镜像队列（复制到多节点）；
> **消费者可靠性（确保消息正确处理）**： 手动确认（关闭自动确认）、死信队列（处理失败的消息路由到此，避免消息堆积或丢失）；
> **网络与集群可靠性**：心跳检测、集群高可用（负载均衡、仲裁队列）；
> **监控与灾备**：监控消息堆积、定期备份；

#### 8.3 rabbitmq的持久性怎么影响性能?
>  **吞吐量下降**、**延迟增加**
>  *  磁盘 I/O 成为瓶颈；
>  *  持久化配置项的影响：
>     队列持久化 (durable=true)，元数据写入磁盘，对性能影响较小。重启后队列不丢失。
>     消息持久化 (deliveryMode=2)	每条消息触发磁盘写入（或 PageCache），高并发时 I/O 压力大。重启后消息不丢失。
>     刷盘策略 (fsync)	强制刷盘（如 lazy 模式）会进一步降低吞吐量，但避免断电丢数据。最高级别持久化（但性能最差）。


# 9 彩穗科技
#### 9.1 场景题？
> 你接入了一个第三方服务，该服务每天发送约 300 万次请求给你们系统。其中，每个请求都包含一个全局唯一的 requestId（一个 40 字节的 UUID 字符串）。如果因为网络中断、超时等原因导致第三方没有收到响应，它会重新发起完全相同的请求（带相同的 requestId），业务上有几个关键限制：
>   1、每个 requestId 表示一次业务处理，例如支付通知、回调、交易同步等。
>   2、你方必须保证对于每个 requestId，只能处理一次（典型的幂等性要求）。
>   3、不能重复请求第三方服务（第三方服务不具备幂等性）
>   4、由于网络波动或响应失败，同一个 requestId 有可能会在不同时间再次被发送过来，甚至有以下复杂时间分布：
>     4.1、绝大部分重复请求会在20 分钟内重发；
>     4.2、一小部分会在1 天内重发；
>     4.3、极个别（例如接口挂起重试）会在一年后突然重发。
> 🤯 关键技术难点：
>   如何快速识别“是否已处理过某 requestId”？
>   如何既不误判（重复处理）又不滥用资源（存一年）？
>   如何兼顾吞吐量、IO压力、成本？
>
> 答案：
> * (1) 分层存储架构：
>   > | 层级       | 存储介质           | 用途         | 过期时间                  | 特点                   |
> | ---------- | ------------------ | ------------ | ------------------------- | ---------------------- |
> | **热数据** | Redis              | 快速幂等校验 | 20分钟（覆盖90%重复请求） | 高性能、低延迟         |
> | **温数据** | MySQL/HBase        | 长期幂等校验 | 1年                       | 成本可控、支持精确查询 |
> | **冷数据** | 数据湖（如AWS S3） | 极端场景兜底 | 1年                       | 低成本、低频访问       |
>   
> * （2）幂等校验：保证重复请求不会改变系统状态，多次执行同一操作的结果与执行一次相同。
>   基于唯一标识符【判断是否重复】、Token 机制【服务端生成一次性 Token，客户端在首次请求时携带该 Token，服务端校验并作废 Token】、状态机校验【将订单状态改成已支付】、消息队列的去重
> * （3）数据存储优化：
>   压缩存储：对 requestId 做哈希（如 SHA-1）后存储，减少空间占用（40字节 -> 20字节）。
>   索引优化：在 MySQL 中对 requestId 哈希值建立唯一索引，防止重复插入。
>   分区策略：按时间或哈希分区，提升查询效率。
> * 异步持久化：
>   使用消息队列（如 Kafka）解耦幂等校验与持久化写入。
>   保证最终一致性：即使写入失败，极端情况下可通过离线任务修复。



# 10 B站一面
#### 10.1 RabbitMQ技术选型：和kafka有什么区别？
> **适合 RabbitMQ 的场景**
>
> - 需要低延迟：如实时订单处理、即时通讯。
> - 复杂路由逻辑：通过 Exchange 实现灵活的路由（Direct/Fanout/Topic/Headers）。
> - 任务队列：结合工作队列模式（Work Queue）实现任务分发（如 Celery）。
> - 轻量级部署：快速搭建中小规模消息系统。
>
> **适合 Kafka 的场景**
>
> - 高吞吐流数据：如日志收集、用户行为跟踪、IoT 设备数据。
> - 事件溯源：需要长期存储和回溯消息（如金融交易流水）。
> - 流处理：与 Flink/Spark Streaming 集成实现实时计算。
> - 大数据集成：作为数据管道连接 Hadoop、数据仓库等。
>
> - **选 RabbitMQ**：
>   需要低延迟、灵活路由、快速搭建消息代理（如电商订单、即时通讯）。
> - **选 Kafka**：
>   需要高吞吐、流处理、长期存储（如日志分析、实时数仓）。
>


#### 10.2 RabbitMQ延迟队列知道吗？什么死信交换机？
> **方案1：TTL + 死信交换机（最常用）**
>
> - 原理：
>   1. 消息设置 `TTL（Time-To-Live）`，过期后自动变成 **死信（Dead Letter）**。
>   2. 死信被路由到指定的死信交换机（DLX），最终投递到目标队列。
>
> - **优点**：无需插件，兼容性好。
>
> - **缺点**：消息过期后才会被消费，**不支持精确时间控制**（如消息A设置5秒，消息B设置10秒，若A未到期，B即使到期也会被阻塞）。
>
> **方案2：rabbitmq-delayed-message-exchange 插件（推荐）**
>
> - 原理：
>
>   1. 安装官方插件，声明 `x-delayed-message` 类型的交换机。
>   2. 发送消息时通过 `x-delay` 头指定延迟时间（毫秒）。
>
> - **优点**：支持**精确到毫秒级**的延迟，消息按到期时间排序投递。
>
> - **缺点**：需额外安装插件。
>
> **死信**:
> 1. 消息被消费者 `reject/nack` 且不重新入队（`requeue=false`）。
> 2. 消息在队列中存活时间超过 `TTL`。
> 3. 队列长度超过限制（`x-max-length`）。
>
> **死信交换机的作用**: 将死信路由到指定队列，实现异常消息处理或延迟队列。

#### 10.3 MQ消息堆积问题?
> | **原因**             | **表现**                   | **典型场景**                   |
> | -------------------- | -------------------------- | ------------------------------ |
> | 消费者处理能力不足   | 队列长度持续增长           | 消费者逻辑复杂或资源不足       |
> | 消费者宕机或网络中断 | 消息未被消费，堆积在队列   | 服务崩溃、机房故障             |
> | 生产者突发流量       | 短时间内消息量激增         | 大促活动、日志爆发             |
> | 死信队列未处理       | 死信队列堆积，占用磁盘空间 | 未监控死信队列或未设置过期时间 |
>
> RabbitMQ 消息堆积解决方案:
>  * 紧急处理：快速消减堆积
>    * 扩容消费者;
>    * 批量消费;
>   
>  * 长期优化：提升消费能力
>    * 异步化处理;
>    * 消息分片;
>    * 死信监控;
>   
>  * 流量控制
>    * 限流生产者;
>    * 队列容量限制;
>   
> Kafka 消息堆积解决方案:
> * 紧急处理:
>   * 扩容分区与消费者;
>   * 跳过堆积消息;
>  
> * 长期优化:
>   * 提高批处理效率;
>   * 并行消费;
>   * 压缩与清理策略;

#### 10.4 MQ乱序问题?
> 消息的消费顺序与发送顺序不一致。
> 原因：多消费者并发处理、消息重试或失败转移【消费者失败后消息重新入队或转入死信队列】、分区/队列负载不均、生产者并行发送	多线程/多节点发送且无顺序控制。
> RabbitMQ 乱序解决方案：
> * 单队列单消费者、 业务ID哈希路由【同一业务ID的消息需有序，不同ID可并行，按业务ID哈希路由到固定队列，确保同一ID的消息由同一消费者处理】、消息版本号控制【消息中携带版本号或时间戳，消费者丢弃过期版本】
> Kafka 乱序解决方案：单分区有序【仅保证单分区内消息顺序】、消费者端顺序队列【消费者将消息按Key存入内存队列，单线程处理每个Key的消息】、事务消息或幂等生产者【生产者重试导致消息重复或乱序，启用Kafka幂等生产者或事务】
> 通用优化策略：
> | **策略**                 | **适用场景**                           | **实现要点**                                                 |
> | ------------------------ | -------------------------------------- | ------------------------------------------------------------ |
> | **局部有序代替全局有序** | 大多数业务场景（如订单维度的顺序）     | 按业务ID哈希路由到队列/分区，牺牲部分并行度。                |
> | **异步队列+同步点**      | 允许短暂乱序但需最终一致（如日志处理） | 消费者处理完成后写入DB前加分布式锁或CAS检查。                |
> | **消息时序数据库**       | 金融/交易类高要求场景                  | 使用支持时序的存储（如InfluxDB）或版本控制，消费时按时间戳重新排序。 |
#### 10.5 布隆过滤器防止雪崩，布隆过滤器原理和实现?
>见3.4


#### 10.6 场景题
> 直播购物遇到的超卖问题如何防止？同时有多个商品秒杀还是什么的业务场景？（不是单纯超卖问题，最后他说可以采用db锁或者是redis解决，但是redis解决还有别的隐患）？

> 超卖问题主要源于三个关键因素：
>
> 1. **并发读写冲突**：当大量用户同时查询库存并下单时，系统可能在库存已耗尽后仍接受订单
> 2. **数据不一致**：缓存层与数据库层的库存数据不同步，导致前端显示库存不准确
> 3. **系统响应延迟**：高并发下系统处理速度跟不上请求量，造成库存计算错误
>
> * 基础防护方案：
> 1. 数据库层面的控制
>
> - **悲观锁机制**：在查询库存时直接锁定数据行，确保同一时间只有一个请求能操作库存。这种方法简单直接但性能较差，适合中小规模活动。
> - **乐观锁机制**：通过版本号控制，只有在库存版本未变化时才允许扣减。这种方法性能较好但需要处理大量失败请求。
> - **条件更新**：在SQL语句中直接设置库存扣减条件（如"库存>0时才扣减"），利用数据库的原子性保证安全。
>
> 2. 缓存层的优化
>
> - **原子操作**：使用Redis的原子命令（如DECR）或Lua脚本执行库存扣减，确保操作的原子性。
> - **库存预热**：将库存拆分为多个"库存桶"分散到不同缓存节点，降低单个节点的压力。
> - **多级缓存**：设置本地缓存+分布式缓存的多层结构，既保证速度又确保一致性。
>
> * 高并发场景进阶方案
>
> 1. 请求流量控制
>
> - **分层过滤**：构建多级防护体系，在接入层就拦截非法请求和过量请求。
> - **队列缓冲**：将瞬时高峰请求放入消息队列，后端服务按处理能力逐步消费。
> - **热点隔离**：为热门商品配置独立的服务集群和存储资源，避免影响其他商品。
>
> 2. 库存分段策略
>
> 将总库存拆分为若干段，每段独立控制。这样可以将全局竞争转化为多个小范围的竞争，显著提高系统并行处理能力。例如将1000件库存分为10个100件的段，不同用户可以同时购买不同段的商品。
>
> 3. 最终一致性方案
>
> 采用"预扣减+异步确认"的模式：先快速扣减缓存中的库存并生成订单，再异步同步到数据库。配合定时任务核对和修正数据，确保最终一致性。
>
> * 用redis的隐患：数据可能丢失、持久化会影响性能、数据库更新失败导致超卖、并发请求导致缓存和数据库状态不同、热点key超过节点承受能力、大量请求集中在某个 Redis 分片。


# 11 百联全渠道+奇富科技
#### 11.1 Redis最大并发量是多少？
> 理论上10万-50万；

#### 11.2 Java的优缺点？
> **优点**：跨平台、生态丰富、内存管理与垃圾回收、多线程与并发支持、强类型与面向对象。
> **缺点**：性能开销大、语法冗长、语法复杂、依赖管理复杂。

#### 11.3 Java有哪些基础类型，每个类型占几个字节？
> | **数据类型** | **关键字** | **字节数**     |
> | ------------ | ---------- | -------------- |
> | 字节型       | `byte`     | **1字节**      |
> | 短整型       | `short`    | **2字节**      |
> | 整型         | `int`      | **4字节**      |
> | 长整型       | `long`     | **8字节**      |
> | 单精度浮点型 | `float`    | **4字节**      |
> | 双精度浮点型 | `double`   | **8字节**      |
> | 字符型       | `char`     | **2字节**      |
> | 布尔型       | `boolean`  | **未严格定义** |

#### 11.4 包装类的好处？
> 让基本类型具备对象特性、提供丰富的工具方法【类型转换、进制转换、大小比较】、支持面向对象编程范式、自动装箱/拆箱、缓存机制优化性能、与集合框架（Collections）兼容

#### 11.5 Integer类型赋值null，接着加一个数，结果是什么？
> 报错，null.intValue()；

#### 11.6 Boolean类型没赋值，直接判断true/false，结果是什么？
> 报错，null.booleanValue()；

#### 11.7 异常的分类?
> 可查异常（Checked Exception）【外部因素导致的错误，必须处理】、运行时异常（Runtime Exception）【程序逻辑错误，可不处理】和 错误（Error） 【JVM 或系统级严重问题，程序通常无法恢复】

#### 11.8 业务中自定义的Exception继承的是运行时异常还是非运行时异常？
> 运行时异常，可以不需要强制处理

#### 11.9 Object类的方法?
> | **方法**          | **作用**               | **是否可重写** |
> | ----------------- | ---------------------- | -------------- |
> | `toString()`      | 返回对象字符串表示     | ✅              |
> | `equals(Object)`  | 比较对象逻辑相等       | ✅              |
> | `hashCode()`      | 返回哈希码             | ✅              |
> | `getClass()`      | 获取运行时类           | ❌              |
> | `clone()`         | 对象浅拷贝             | ✅              |
> | `finalize()`      | 垃圾回收前调用（废弃） | ✅              |
> | `wait()/notify()` | 线程间通信             | ❌              |

#### 11.10 String类的hashCode返回的是什么?
> 32 位有符号整数，它是根据字符串的字符内容计算出的哈希值。

#### 11.11 全局异常处理器?
> 一种集中处理应用程序中所有异常的机制。无需在每个方法中手动 try-catch。
> ```java
> @ControllerAdvice // 声明全局异常处理器
> public class GlobalExceptionHandler {
>     // 处理特定异常（如 NullPointerException）
>     @ExceptionHandler(NullPointerException.class)
>     public ResponseEntity<ErrorResponse> handleNullPointerException(NullPointerException ex) {
>         ErrorResponse error = new ErrorResponse(
>             HttpStatus.BAD_REQUEST.value(),
>             "NullPointerException occurred",
>             ex.getMessage()
>         );
>         return new ResponseEntity<>(error, HttpStatus.BAD_REQUEST);
>     }
> 
> ```
#### 11.12 联合索引(a,b)什么时候会失效?
> 不遵循最左匹配原则；
> 对索引列进行计算、函数或类型转换；
> 使用 OR 条件`WHERE a = 1 OR c = 3`；
> 使用 !=、<>、NOT IN、NOT EXISTS；
> 使用 LIKE 以 % 开头；
> 数据量太少，优化器放弃索引

#### 11.13 select * from 表名 where a=？and b=？ a和b分开建索引，那么最后会走单个索引还是两个索引都走？
> 选择其中一个索引【通常是选择性更高(列的不同值多)的那个】，而 不会同时使用两个索引。














